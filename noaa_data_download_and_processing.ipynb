{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "noaa_data download and processing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevegbrooks/commodify/blob/main/noaa_data_download_and_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1so9ZQGmADAK"
      },
      "source": [
        "## 0. Download NCEI NOAA weather data via wget "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33vmZ4l5ADAO"
      },
      "source": [
        "Data download via wget on command prompt (Refer to https://eternallybored.org/misc/wget/)\n",
        "\n",
        "Command: \n",
        "wget -r --no-parent --reject \"index.html*\" https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/{1929..2021}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86wcVARADAP"
      },
      "source": [
        "## 1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFKi-hfNADAQ"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdC9N2yMADAQ"
      },
      "source": [
        "## 2. User inputs (directories, years to process) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "D3fYnDhhADAR"
      },
      "source": [
        "# User input\n",
        "input_dir = r\"C:\\cygwin64\\home\\irtx\\www.ncei.noaa.gov\\data\\global-summary-of-the-day\\access\"\n",
        "start_year = 1929\n",
        "end_year = 2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfkEULEADAS"
      },
      "source": [
        "## 3. Process data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v_Wf5FkADAS"
      },
      "source": [
        "li = []    # empty list to store dataframes\n",
        "\n",
        "# Loop to process files in each folder (by year)\n",
        "for i in range(start_year,end_year+1):\n",
        "    filepath = \"{0}\\{1}\".format(input_dir, i)\n",
        "    print(\"Processing year {0}/{1}...\".format(i,end_year),end='\\r')\n",
        "    \n",
        "    for file in os.listdir(filepath):\n",
        "        \n",
        "        if file.endswith(\".csv\"):\n",
        "            df = pd.read_csv(filepath + '/' + file, index_col=None, header=0)\n",
        "            \n",
        "            # Only append df if station is in USA\n",
        "            try:\n",
        "                if (df['NAME'][0].endswith(\"US\")):\n",
        "                    li.append(df)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "# Combine dfs into one main df - 'usa'\n",
        "usa = pd.concat(li, axis=0, ignore_index=True)\n",
        "usa['STATE']=usa['NAME'].str[-5:-3]\n",
        "usa['DATE']= pd.to_datetime(usa['DATE'])\n",
        "usa.index = pd.to_datetime(usa['DATE'],format='%y-%m-%d')\n",
        "\n",
        "# Only keep rows with correct STATE values\n",
        "us_states = ['AK', 'AL', 'AR', 'AS', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', \n",
        "             'GA', 'GU', 'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', \n",
        "             'MD', 'ME', 'MI', 'MN', 'MO', 'MP', 'MS', 'MT', 'NC', 'ND', 'NE', \n",
        "             'NH', 'NJ', 'NM', 'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'PR', 'RI', \n",
        "             'SC', 'SD', 'TN', 'TX', 'UM', 'UT', 'VA', 'VI', 'VT', 'WA', 'WI', \n",
        "             'WV', 'WY']\n",
        "\n",
        "pattern = '|'.join(us_states)\n",
        "usa = usa[usa['STATE'].str.contains(pattern)]\n",
        "\n",
        "# Save out useful attributes, and calculate monthly mean values\n",
        "usa = usa[['DATE','TEMP','DEWP','SLP','WDSP','MXSPD','GUST','PRCP','SNDP','FRSHTT','STATE']]\n",
        "usa = usa.groupby(by=[usa.index.year, usa.index.month, usa.STATE]).mean()\n",
        "usa.index.set_names([\"YEAR\", \"MONTH\", \"STATE\"], inplace=True)\n",
        "\n",
        "# Replace placeholder values (9999.9, 999.9, 99.9) with N/A\n",
        "for i in ['SLP','DEWP']:\n",
        "    mask = usa[i] > 9999\n",
        "    usa.loc[mask, i] = np.nan\n",
        "\n",
        "for i in ['SNDP','GUST']:\n",
        "    mask = usa[i] > 999\n",
        "    usa.loc[mask, i] = np.nan\n",
        "\n",
        "mask = usa['PRCP'] > 99\n",
        "usa.loc[mask, 'PRCP'] = np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhFnNcBAADAT"
      },
      "source": [
        "## 4. Export CSV (monthly means in USA states)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZCZn9P5ADAU"
      },
      "source": [
        "#Export processed file as csv\n",
        "usa.to_csv(\"{0}\\processed_usa_{1}-{2}.csv\".format(input_dir,start_year,end_year))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}